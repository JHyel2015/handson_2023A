{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 12 Advanced Recurrent Neural Networks\n",
    "\n",
    "Advanced Neural Network architectures represent significant advancements in the field of deep learning, which are most used in the domain of sequence modeling and processing. These architectures build upon the traditional feedforward neural networks and introduce recurrent connections, allowing them to exhibit temporal dynamics and memory capabilities.\n",
    "\n",
    "* The Elman RNN employs a simple recurrent loop in its hidden layer, enabling it to capture short-term temporal dependencies, making it suitable for applications such as speech recognition and time series analysis.\n",
    "* The Jordan RNN possesses feedback connections from the output layer to the hidden layer, rendering it capable of modeling longer-term dependencies, which finds applications in machine translation and language modeling tasks.\n",
    "* The Bidirectional RNN combines both forward and backward temporal processing, allowing it to consider both past and future context in its predictions, making it effective in natural language processing tasks such as sentiment analysis and named entity recognition.\n",
    "\n",
    "These advanced neural network architectures significantly expand the modeling capabilities of traditional neural networks and have become indispensable tools in various sequential data processing applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Exercise\n",
    "Use the IMDB movie reviews dataset to perform sentiment analysis with a Elman, Jordan and Bidirectional RNN.\n",
    "Highlight the differences on the performance of each architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras_preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense, Bidirectional\n",
    "from keras.utils.data_utils import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. Load the IMDB movie reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_features = 5000  # Number of words to consider as features\n",
    "max_len_short = 100  # Maximum sequence length for short sequences\n",
    "max_len_long = 500   # Maximum sequence length for long sequences\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2. Pad sequences to a fixed length for RNN input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_short = sequence.pad_sequences(x_train, maxlen=max_len_short)\n",
    "x_test_short = sequence.pad_sequences(x_test, maxlen=max_len_short)\n",
    "\n",
    "x_train_long = sequence.pad_sequences(x_train, maxlen=max_len_long)\n",
    "x_test_long = sequence.pad_sequences(x_test, maxlen=max_len_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "3. Build the distinct RNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_elman_rnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 32))\n",
    "    model.add(SimpleRNN(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def build_jordan_rnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 32))\n",
    "    model.add(SimpleRNN(32, activation='relu', return_sequences=True))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def build_bidirectional_rnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 32))\n",
    "    model.add(Bidirectional(SimpleRNN(32, activation='relu')))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "4. Train and evaluate the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "    return loss, accuracy, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "5. Train and evaluate the RNN model on short sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RNN model on short sequences:\n",
      "Epoch 1/5\n",
      "157/157 [==============================] - 5s 27ms/step - loss: 0.6136 - accuracy: 0.6597 - val_loss: 0.4485 - val_accuracy: 0.7988\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 4s 29ms/step - loss: 0.3595 - accuracy: 0.8440 - val_loss: 0.3490 - val_accuracy: 0.8422\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.2723 - accuracy: 0.8882 - val_loss: 0.3876 - val_accuracy: 0.8266\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.2311 - accuracy: 0.9084 - val_loss: 0.3602 - val_accuracy: 0.8370\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.2141 - accuracy: 0.9156 - val_loss: 0.3987 - val_accuracy: 0.8378\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.3957 - accuracy: 0.8412\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining RNN model on short sequences:\")\n",
    "rnn_model_short = build_elman_rnn_model()\n",
    "loss_short, accuracy_short, history_short = train_and_evaluate_model(\n",
    "    rnn_model_short, x_train_short, y_train, x_test_short, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "6. Train and evaluate the RNN model on long sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Elman RNN model on long sequences:\n",
      "Epoch 1/5\n",
      "157/157 [==============================] - 27s 158ms/step - loss: 0.7234 - accuracy: 0.5771 - val_loss: 0.6648 - val_accuracy: 0.6326\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.5036 - accuracy: 0.7742 - val_loss: 0.3834 - val_accuracy: 0.8436\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.3067 - accuracy: 0.8719 - val_loss: 0.3270 - val_accuracy: 0.8522\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 32s 204ms/step - loss: 0.3025 - accuracy: 0.8697 - val_loss: 0.3452 - val_accuracy: 0.8380\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 46s 292ms/step - loss: 0.2270 - accuracy: 0.9082 - val_loss: 0.3280 - val_accuracy: 0.8596\n",
      "782/782 [==============================] - 41s 52ms/step - loss: 0.3392 - accuracy: 0.8575\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining Elman RNN model on long sequences:\")\n",
    "rnn_model_long = build_elman_rnn_model()\n",
    "loss_long, accuracy_long, history_long = train_and_evaluate_model(\n",
    "    rnn_model_long, x_train_long, y_train, x_test_long, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "7. Compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results on Short Sequences:\n",
      "Loss: 0.4152, Accuracy: 0.8406\n",
      "\n",
      "Results on Long Sequences:\n",
      "Loss: 0.3697, Accuracy: 0.8423\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResults on Short Sequences:\")\n",
    "print(f\"Loss: {loss_short:.4f}, Accuracy: {accuracy_short:.4f}\")\n",
    "\n",
    "print(\"\\nResults on Long Sequences:\")\n",
    "print(f\"Loss: {loss_long:.4f}, Accuracy: {accuracy_long:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
